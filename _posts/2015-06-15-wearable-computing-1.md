---
title: 'Wearable Computing'
date: 2015-06-15
permalink: /posts/experiments-in-wearable-computing
tags:
  - wearable computing
  - Masters Thesis
  - University of Toronto
  - Steve Mann
  - Augmented Reality
  - BCI
  - Dementia
  - Computer Engineering
---

I got to work with the father of wearable computing Prof Steve Mann(link) on lots of wearables such as Meta Spaceglasses(not Facebook). 
One of the first projects I worked on was visualising the sightfield of a camera. It is basically visualisation of the region visible to a camera. It's scientific name is veillance flux.
Image
We worked on the mobile prototype of the same. Using Android phones n ios phones, we connected the camera to a light stick( called bugbroom). And via led lights we take a long exposure picturr of the light stick resulting in visualisation of sightfield of camera.
We showcased this project at augmented world expo and Meta Spaceglasses headquarters.
After this project, we worked with Microsoft kinect depth cameras for AR game setup.


Some of the people from the lab utilised AR concept to make Yahoo finance based AR terminal. A terminal showcases news, stock price, etc. in separate windows or on different monitors.
 We won first prize for Epson Moverio AR glass challenge Note, currently Apple Vision Pro supports Bloomberg terminal that is similar.
The main advantage of this concept is that multi monitors can be replaced by a single AR glass.
Next, as part of the masters project, we utilised the concept of time integral of distance( called absement) based fitness exercises based system ( called MannFit) .
The prototypes included a wobble board n hanging bars. The concept can be understood  as the distance increases with time absement increases. The goal is to minimise distance or instability on a wobble board or hanging bars.
These kind of exercises require not just strength but balance As well. If the wobble board is stable the distance is zero, so the absement is zero.
We  showcased the game at IEEE GEM 2014, the gaming conference.
I got chance to interact with other wearables such as myo arm band based on EMG.
Next, we used BCI ( brain computer interface) , a meditation band based on EEG called Muse. I helped develop the neural networks based drowsiness detection android mobile app that used EEG to detect drowsiness.
Next, we worked on an app to measure creativity ( Divergent) using EEG.  We collected user responses to find alternative uses to common objects. Based on the gathered data, we trained a neural network to light up a bulb based on EEG signals if a creative idea occurred.
We showcased the concept at IEEE GEM 2015.

Next, we participated in facebook Dementia Hackathon.People with dementia tend to forget names as the disease progresses. We utilised facial recognition based prototype to identify faces and their names using an AR glass.